#Required Packages
require(caret)
require(tm)
require(wordcloud)
require(e1071)
require(MLmetrics)

rawData <-  read.csv("sms_raw_NB.csv", 
                     header = FALSE, 
                     stringsAsFactors = FALSE)
#Show the structure of the raw dataset
str(rawData)

#Changing the name of the features/ columns
colnames(rawData) <- c("type", "text")

#Converting the text to utf-8 format
rawData$text <- iconv(rawData$text, to = "utf-8")

#Type as factor
rawData$type <- factor(rawData$type)

summary(rawData)

#Show the type of messages and their distributions
table(rawData$type)

#as percentage over the total messages
prop.table(table(rawData$type)) * 100
#the data is unbalanced, there are lot of messages classifed as ham and few messages as spam.

#the data is split into 
#a training and testing dataset. 
#The training dataset is going to be used 
#for exploring the data and unserstanding 
#the type of cleaning, 
#transformation rules then need to be applied 
#in order to create the relevant features 
#to train the model/ classifier.

#The data splitting is done using 
#a stratified sampling approach, 
#to keep the same proportions of the 
#type of messages within the training and 
#testing datasets.

set.seed(1234)
#Create a training set containing 75% of the data (with stratified sampling)
trainIndex <- createDataPartition(rawData$type, p = .75, 
                                  list = FALSE, 
                                  times = 1)
trainData <- rawData[trainIndex,]
testData <- rawData[-trainIndex,]

#proportion in train dataset
prop.table(table(trainData$type)) * 100
#proportion in test dataset
prop.table(table(testData$type)) * 100

#Exploratory data analysis is done 
#on the training dataset only in order to have 
#an hold out dataset, the testing dataset, 
#that can be used to evaluate the trained model 
#on a completely new set of data.
#Hame messages
trainData_ham <- trainData[trainData$type == "ham",]
head(trainData_ham$text)
tail(trainData_ham$text)

#spam messages
trainData_spam <- trainData[trainData$type == "spam",]
head(trainData_spam$text)
tail(trainData_spam$text)

trainData_spam <- NULL
trainData_ham <- NULL

#Cleaning the data
#The tm package - Text Mining package in R 
#- is used for such purpose. 
#Optionally the tidytext package could be used 
#for working with tidy data.

#create the corpus
corpus <- Corpus(VectorSource(trainData$text))
#basic info about the corpus
print(corpus)

#Inspect 4 documents
corpus[[1]]$content
corpus[[2]]$content
corpus[[50]]$content
corpus[[100]]$content

#1. normalize to lowercase (not a standard tm transformation)
corpus <- tm_map(corpus, content_transformer(tolower))
#2. remove numbers
corpus <- tm_map(corpus, removeNumbers)
#3. remove stopwords e.g. to, and, but, or (using predefined set of word in tm package)
corpus <- tm_map(corpus, removeWords, stopwords())
#4. remove punctuation
corpus <- tm_map(corpus, removePunctuation)
#5. normalize whitespaces
corpus <- tm_map(corpus, stripWhitespace)

#Inspect the same 4 documents to visualize how the documents have been
#transformed
corpus[[1]]$content
corpus[[2]]$content
corpus[[50]]$content
corpus[[100]]$content

#Visual Analysis of the high frequency words 
#(ham vs. spam)
#Another interesting visualization involves 
#comparing the clouds of SMS spam and ham .

pal1 <- brewer.pal(9,"YlGn")
pal1 <- pal1[-(1:4)]

pal2 <- brewer.pal(9,"Reds")
pal2 <- pal2[-(1:4)]

#min.freq initial settings -> around 10% of the number of docs in the corpus (40 times)
par(mfrow = c(1,2))
wordcloud(corpus[trainData$type == "ham"], min.freq = 40, random.order = FALSE, colors = pal1)
wordcloud(corpus[trainData$type == "spam"], min.freq = 5, random.order = FALSE, colors = pal2)

#Feature Engineering
#Transforming the data: tokenization
#Now that the messages are processed to our liking, 
#the next step is to split the messages into 
#individual elements through a process called 
#tokenization. A token is a single element of 
#a text string; in this case, the tokens are words.

#From the corpus a data structured called sparse matrix 
#is created. In the sparse matrix, each row (observation) 
#represents a document (SMS text message) and each column 
#is a token/ word. The number in a cell represents 
#the number of time the token (col) is present in the 
#document represented by that row.

#Creation of the DTM considering terms with at least 2 chars
sms_dtm <- DocumentTermMatrix(corpus, control = list(global = c(2, Inf)))
#basic information about the sparse matrix
print(sms_dtm)

#To have an idea of the content of the document term matrix
inspect(sms_dtm[1:10, 5:13])

sms_features <- findFreqTerms(sms_dtm, 5) #find words that appears at least 5 times
summary(sms_features)
head(sms_features)

# limit our training and test matrix to only the words 
#in the dictionary of frequent terms
sms_dtm_train <- DocumentTermMatrix(corpus, list(global = c(2, Inf), dictionary = sms_features))
print(sms_dtm_train)

convert_counts <- function(x){
  x <- ifelse(x > 0, 1, 0)
  x <- factor(x, levels = c(0,1), labels = c("No", "Yes"))
  return (x)
}
sms_dtm_train <- apply(sms_dtm_train, MARGIN = 2, convert_counts)

head(sms_dtm_train[,1:5])

#Train the model
sms_classifier <- naiveBayes(sms_dtm_train, trainData$type)
sms_classifier[[2]][1:5]

#Evaluate the model
#Cleaning & Feature Engineering
corpus <- Corpus(VectorSource(testData$text))
#1. normalize to lowercase (not a standard tm transformation)
corpus <- tm_map(corpus, content_transformer(tolower))
#2. remove numbers
corpus <- tm_map(corpus, removeNumbers)
#3. remove stopwords e.g. to, and, but, or (using predefined set of word in tm package)
corpus <- tm_map(corpus, removeWords, stopwords())
#4. remove punctuation
corpus <- tm_map(corpus, removePunctuation)
#5. normalize whitespaces
corpus <- tm_map(corpus, stripWhitespace)

sms_dtm_test <- DocumentTermMatrix(corpus, list(global = c(2, Inf), dictionary = sms_features))
print(sms_dtm_test)

sms_dtm_test <- apply(sms_dtm_test, MARGIN = 2, convert_counts)
sms_dtm_test[1:10, 5:12]

#Evaluate the model
sms_test_pred <- predict(sms_classifier, sms_dtm_test)

#table actual (row) vs. predicted (col): confusion matrix
table(testData$type, sms_test_pred)


ConfusionMatrix(sms_test_pred, testData$type)


Accuracy(sms_test_pred, testData$type)
## [1] 0.9784017

F1_Score(sms_test_pred, testData$type)
## [1] 0.9876442
